import pyrealsense2 as rs
import numpy as np
import cv2

# Configure Intel RealSense camera
pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)

# Start streaming
pipeline.start(config)

def region_of_interest_left(image):
    height = image.shape[0]
    polygons = np.array([
        [(0, height), (300, height // 2), (400, height // 2), (200, height)]
    ])
    mask = np.zeros_like(image)
    cv2.fillPoly(mask, polygons, 255)
    return cv2.bitwise_and(image, mask)

def region_of_interest_right(image):
    height = image.shape[0]
    polygons = np.array([
        [(540, height), (400, height // 2), (500, height // 2), (640, height)]
    ])
    mask = np.zeros_like(image)
    cv2.fillPoly(mask, polygons, 255)
    return cv2.bitwise_and(image, mask)

def display_lines(image, lines):
    line_image = np.zeros_like(image)
    if lines is not None:
        for line in lines:
            x1, y1, x2, y2 = line.reshape(4)
            cv2.line(line_image, (x1, y1), (x2, y2), (0, 0, 255), 10)
    return line_image

def make_coordinates(image, line_parameters):
    slope, intercept = line_parameters
    y1 = image.shape[0]
    y2 = int(y1 * (3 / 5))
    x1 = int((y1 - intercept) / slope)
    x2 = int((y2 - intercept) / slope)
    return np.array([x1, y1, x2, y2])

def average_slope_intercept(image, lines, left=True):
    fit = []
    for line in lines:
        x1, y1, x2, y2 = line.reshape(4)
        parameters = np.polyfit((x1, x2), (y1, y2), 1)
        slope = parameters[0]
        intercept = parameters[1]
        if (left and slope < 0) or (not left and slope > 0):
            fit.append((slope, intercept))

    if len(fit) > 0:
        fit_average = np.average(fit, axis=0)
        return make_coordinates(image, fit_average)
    else:
        return np.array([0, 0, 0, 0])

try:
    while True:
        # Get frames from the camera
        frames = pipeline.wait_for_frames()
        color_frame = frames.get_color_frame()
        if not color_frame:
            continue

        # Convert to numpy array
        frame = np.asanyarray(color_frame.get_data())

        # Process frame for lane detection
        lane_image = np.copy(frame)
        gray = cv2.cvtColor(lane_image, cv2.COLOR_BGR2GRAY)
        blur = cv2.GaussianBlur(gray, (5, 5), 0)
        canny = cv2.Canny(blur, 50, 150)

        # Apply region of interest for left and right lanes
        cropped_image_left = region_of_interest_left(canny)
        cropped_image_right = region_of_interest_right(canny)

        # Detect lines in each region
        lines_left = cv2.HoughLinesP(cropped_image_left, 2, np.pi / 180, 100, minLineLength=10, maxLineGap=5)
        lines_right = cv2.HoughLinesP(cropped_image_right, 2, np.pi / 180, 100, minLineLength=10, maxLineGap=5)

        # Average lines for left and right lanes
        if lines_left is not None:
            averaged_left_line = np.array([average_slope_intercept(lane_image, lines_left, left=True)])
        else:
            averaged_left_line = np.array([[0, 0, 0, 0]])

        if lines_right is not None:
            averaged_right_line = np.array([average_slope_intercept(lane_image, lines_right, left=False)])
        else:
            averaged_right_line = np.array([[0, 0, 0, 0]])

        # Display detected left and right lanes
        left_line_image = display_lines(lane_image, averaged_left_line)
        right_line_image = display_lines(lane_image, averaged_right_line)

        # Combine lane lines with original image
        combo_image = cv2.addWeighted(lane_image, 0.8, left_line_image, 1, 1)
        combo_image = cv2.addWeighted(combo_image, 1, right_line_image, 1, 1)

        # Show the image
        cv2.imshow('Lane Detection', combo_image)

        # Exit loop if 'q' is pressed
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
finally:
    # Stop streaming
    pipeline.stop()
    cv2.destroyAllWindows()
